{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "## preprocessing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "input_file_dir = \"/Users/ninglee/Documents/IntrutionDection/datasets\"\n",
    "train_file_name = \"kddcup.data_10_percent.txt\"\n",
    "test_file_name = \"corrected.txt\"\n",
    "header_file_name = \"header.txt\"\n",
    "train_files = os.path.join(input_file_dir, train_file_name)\n",
    "test_files = os.path.join(input_file_dir, test_file_name)\n",
    "header_files = os.path.join(input_file_dir, header_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(header_files, 'r') as f:\n",
    "    header = f.readline().strip().split(',')\n",
    "train_dataset = pd.read_csv(train_files)\n",
    "test_dataset = pd.read_csv(test_files)\n",
    "train_dataset.columns = header\n",
    "test_dataset.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494020 311028\n"
     ]
    }
   ],
   "source": [
    "train_dataset_size = train_dataset.shape[0]\n",
    "test_dataset_size = test_dataset.shape[0]\n",
    "train_dataset = pd.concat([train_dataset, test_dataset], axis=0)\n",
    "print train_dataset_size, test_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805048, 42)\n"
     ]
    }
   ],
   "source": [
    "print train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_map(label):\n",
    "    label = str(label).split('.')[0]\n",
    "    if label == 'normal':\n",
    "        return 0\n",
    "    if label in ['ipsweep', 'mscan', 'nmap', 'portsweep', 'saint', 'satan']: #PROBE\n",
    "        return 1\n",
    "    if label in ['apache2', 'back', 'land', 'mailbomb', 'neptune', 'pod', 'processtable', 'smurf', 'teardrop', 'udpstorm']: #DOS\n",
    "        return 2\n",
    "    if label in ['buffer_overflow', 'httptunnel', 'loadmodule', 'perl', 'ps', 'rootkit', 'sqlattack', 'xterm']: #U2R\n",
    "        return 3\n",
    "    if label in ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'named', 'phf', 'sendmail', 'snmpgetattack', 'snmpguess', 'spy', 'warezclient', 'warezmaster', 'worm', 'xlock', 'xsnoop']: #R2L\n",
    "        return 4\n",
    "    \n",
    "train_dataset['labels'] = train_dataset['labels'].apply(labels_map)\n",
    "labels_dummies = pd.get_dummies(train_dataset['labels'], prefix='label')\n",
    "train_dataset = pd.concat([train_dataset,labels_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        239        486     0   \n",
       "1         0           tcp    http   SF        235       1337     0   \n",
       "2         0           tcp    http   SF        219       1337     0   \n",
       "3         0           tcp    http   SF        217       2032     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot   ...     dst_host_serror_rate  \\\n",
       "0               0       0    0   ...                      0.0   \n",
       "1               0       0    0   ...                      0.0   \n",
       "2               0       0    0   ...                      0.0   \n",
       "3               0       0    0   ...                      0.0   \n",
       "4               0       0    0   ...                      0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                   0.0                       0.0   \n",
       "1                       0.0                   0.0                       0.0   \n",
       "2                       0.0                   0.0                       0.0   \n",
       "3                       0.0                   0.0                       0.0   \n",
       "4                       0.0                   0.0                       0.0   \n",
       "\n",
       "   labels  label_0  label_1  label_2  label_3  label_4  \n",
       "0       0        1        0        0        0        0  \n",
       "1       0        1        0        0        0        0  \n",
       "2       0        1        0        0        0        0  \n",
       "3       0        1        0        0        0        0  \n",
       "4       0        1        0        0        0        0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocal_type_dummies = pd.get_dummies(train_dataset.protocol_type, prefix='protocol_type')\n",
    "service_dummies = pd.get_dummies(train_dataset.service, prefix='service')\n",
    "flag_dummies = pd.get_dummies(train_dataset.flag, prefix='flag')\n",
    "train_dataset = pd.concat([train_dataset, protocal_type_dummies, service_dummies, flag_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max1 = train_dataset.src_bytes.max(); min1 = train_dataset.src_bytes.min();\n",
    "max2 = train_dataset.dst_bytes.max(); min2 = train_dataset.dst_bytes.min();\n",
    "train_dataset['src_bytes_norm'] = (train_dataset.src_bytes - min1) / float(max1 - min1)\n",
    "train_dataset['dst_bytes_norm'] = (train_dataset.dst_bytes - min2) / float(max2 - min2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop(['protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes','labels'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype('float')\n",
    "# train_dataset = (train_dataset - train_dataset.min()) / (train_dataset.max() - train_dataset.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_train_dataset = train_dataset.iloc[:train_dataset_size, :].sample(n=200000)\n",
    "# sub_test_dataset = train_dataset.iloc[train_dataset_size:, :].sample(n=50000)\n",
    "\n",
    "sub_train_dataset = train_dataset.iloc[:train_dataset_size, :].sample(n=490000)\n",
    "sub_test_dataset = train_dataset.iloc[train_dataset_size:, :].sample(n=310000)\n",
    "\n",
    "sub_train_labels = sub_train_dataset[['label_0', 'label_1', 'label_2', 'label_3', 'label_4']]\n",
    "sub_test_labels = sub_test_dataset[['label_0', 'label_1', 'label_2', 'label_3', 'label_4']]\n",
    "sub_train_dataset.drop(['label_0', 'label_1', 'label_2', 'label_3', 'label_4'], axis=1, inplace=True)\n",
    "sub_test_dataset.drop(['label_0', 'label_1', 'label_2', 'label_3', 'label_4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = train_dataset.iloc[train_dataset_size:,:]\n",
    "train_dataset = train_dataset.iloc[:train_dataset_size, :]\n",
    "train_labels = train_dataset[['label_0', 'label_1', 'label_2', 'label_3', 'label_4']]\n",
    "test_labels = test_dataset[['label_0', 'label_1', 'label_2', 'label_3', 'label_4']]\n",
    "train_dataset.drop(['label_0', 'label_1', 'label_2', 'label_3', 'label_4'], axis=1, inplace=True)\n",
    "test_dataset.drop(['label_0', 'label_1', 'label_2', 'label_3', 'label_4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494020, 119) (494020, 5)\n",
      "(311028, 119) (311028, 5)\n"
     ]
    }
   ],
   "source": [
    "print train_dataset.shape, train_labels.shape\n",
    "print test_dataset.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490000, 119) (490000, 5)\n",
      "(310000, 119) (310000, 5)\n"
     ]
    }
   ],
   "source": [
    "print sub_train_dataset.shape, sub_train_labels.shape\n",
    "print sub_test_dataset.shape, sub_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>src_bytes_norm</th>\n",
       "      <th>dst_bytes_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  land  wrong_fragment  urgent  hot  num_failed_logins  \\\n",
       "263139       0.0   0.0             0.0     0.0  0.0                0.0   \n",
       "211434       0.0   0.0             0.0     0.0  0.0                0.0   \n",
       "278148       0.0   0.0             0.0     0.0  0.0                0.0   \n",
       "380215       0.0   0.0             0.0     0.0  0.0                0.0   \n",
       "46798        0.0   0.0             0.0     0.0  0.0                0.0   \n",
       "\n",
       "        logged_in  num_compromised  root_shell  su_attempted       ...        \\\n",
       "263139        0.0              0.0         0.0           0.0       ...         \n",
       "211434        0.0              0.0         0.0           0.0       ...         \n",
       "278148        0.0              0.0         0.0           0.0       ...         \n",
       "380215        0.0              0.0         0.0           0.0       ...         \n",
       "46798         0.0              0.0         0.0           0.0       ...         \n",
       "\n",
       "        flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "263139          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "211434          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "278148          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "380215          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "46798           0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "        flag_SH  src_bytes_norm  dst_bytes_norm  \n",
       "263139      0.0        0.000001             0.0  \n",
       "211434      0.0        0.000001             0.0  \n",
       "278148      0.0        0.000001             0.0  \n",
       "380215      0.0        0.000000             0.0  \n",
       "46798       0.0        0.000001             0.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_dataset.describe()\n",
    "sub_train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model1: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "feature_size = 119\n",
    "num_labels = 5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, feature_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "#   tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(sub_test_dataset.values[:,:])\n",
    "  \n",
    "  # Variables.\n",
    "  hidden_weights = tf.Variable(\n",
    "    tf.truncated_normal([feature_size, 512]))\n",
    "  output_weights = tf.Variable(\n",
    "    tf.truncated_normal([512, num_labels]))\n",
    "  weights = [hidden_weights, output_weights]\n",
    "  hidden_biases = tf.Variable(tf.zeros([512]))\n",
    "  output_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  biases = [hidden_biases, output_biases]\n",
    "  \n",
    "  # Training computation.\n",
    "  hidden_layer = tf.add(tf.matmul(tf_train_dataset, tf.cast(weights[0], tf.float32)), biases[0])\n",
    "  hidden_layer = tf.nn.relu(hidden_layer)\n",
    "  hidden_layer = tf.nn.dropout(hidden_layer, 0.5)\n",
    "  logits = tf.add(tf.matmul(hidden_layer, tf.cast(weights[1], tf.float32)), biases[1])\n",
    "#   logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "  l2Loss = tf.nn.l2_loss(weights[0]) + tf.nn.l2_loss(weights[1])\n",
    "  loss = loss + 20*l2Loss\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)#5e-3\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "  # ValidPrediction\n",
    "#   temp1 = tf.add(tf.matmul(tf_valid_dataset, weights[0]), biases[0])\n",
    "#   hidden_temp = tf.nn.relu(temp1)\n",
    "#   temp2 = tf.add(tf.matmul(hidden_temp,weights[1]), biases[1])\n",
    "#   valid_prediction = tf.nn.softmax(temp2)\n",
    "\n",
    "  # TestPrediction\n",
    "  temp3 = tf.add(tf.matmul(tf.cast(tf_test_dataset, tf.float32), weights[0]), biases[0])\n",
    "  hidden_temp2 = tf.nn.relu(temp3)\n",
    "  temp4 = tf.add(tf.matmul(tf.cast(hidden_temp2, tf.float32), weights[1]), biases[1])\n",
    "  test_prediction = tf.nn.softmax(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 506433.937500\n",
      "Minibatch accuracy: 18.4%\n",
      "Test accuracy: 73.9%\n",
      "Minibatch loss at step 300: 0.497526\n",
      "Minibatch accuracy: 98.0%\n",
      "Test accuracy: 89.7%\n",
      "Minibatch loss at step 600: 0.454127\n",
      "Minibatch accuracy: 98.0%\n",
      "Test accuracy: 89.9%\n",
      "Minibatch loss at step 900: 0.486649\n",
      "Minibatch accuracy: 98.4%\n",
      "Test accuracy: 90.0%\n",
      "Minibatch loss at step 1200: 0.457104\n",
      "Minibatch accuracy: 96.9%\n",
      "Test accuracy: 90.0%\n",
      "Minibatch loss at step 1500: 0.473501\n",
      "Minibatch accuracy: 96.1%\n",
      "Test accuracy: 90.0%\n",
      "Minibatch loss at step 1800: 0.392884\n",
      "Minibatch accuracy: 98.8%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 2100: 0.419733\n",
      "Minibatch accuracy: 96.5%\n",
      "Test accuracy: 89.2%\n",
      "Minibatch loss at step 2400: 0.407339\n",
      "Minibatch accuracy: 98.0%\n",
      "Test accuracy: 89.4%\n",
      "Minibatch loss at step 2700: 0.416969\n",
      "Minibatch accuracy: 97.7%\n",
      "Test accuracy: 90.3%\n",
      "Minibatch loss at step 3000: 0.335570\n",
      "Minibatch accuracy: 99.2%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 3300: 0.423369\n",
      "Minibatch accuracy: 97.3%\n",
      "Test accuracy: 90.4%\n",
      "Minibatch loss at step 3600: 0.380348\n",
      "Minibatch accuracy: 98.4%\n",
      "Test accuracy: 90.4%\n",
      "Minibatch loss at step 3900: 0.359902\n",
      "Minibatch accuracy: 98.8%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 4200: 0.367718\n",
      "Minibatch accuracy: 98.4%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 4500: 0.385218\n",
      "Minibatch accuracy: 96.1%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 4800: 0.365142\n",
      "Minibatch accuracy: 97.7%\n",
      "Test accuracy: 88.7%\n",
      "Minibatch loss at step 5100: 0.351854\n",
      "Minibatch accuracy: 98.8%\n",
      "Test accuracy: 90.3%\n",
      "Minibatch loss at step 5400: 0.361016\n",
      "Minibatch accuracy: 98.0%\n",
      "Test accuracy: 89.5%\n",
      "Minibatch loss at step 5700: 0.377942\n",
      "Minibatch accuracy: 97.7%\n",
      "Test accuracy: 90.2%\n",
      "Minibatch loss at step 6000: 0.331762\n",
      "Minibatch accuracy: 98.8%\n",
      "Test accuracy: 90.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  #tf.initialize_all_variables().run()\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (sub_train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = sub_train_dataset.iloc[offset:(offset + batch_size), :].values[:,:]\n",
    "    batch_labels = sub_train_labels.iloc[offset:(offset + batch_size), :].values[:,:]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 300 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "#       print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "#         valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), sub_test_labels.values[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
